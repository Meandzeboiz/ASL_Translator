# ASL_Translator
This AI is trained to recognize American Sign Language (ASL) fingerspelling in static images. What sets it apart from the models it was based on is the custom dataset that is in simple terms two datasets combined. after training, the program should be able to reliably and consisently recognize letters, numbers and some special gestures such as space and delete, as well as detect when there is nothing onscreen. This is a complete program albeit a very simple and common project in the end. if I had more time I would have taken time to learn how to make it detect rapid ASL fingerspelling in live camera feed
as well as having it type out outputted letters, numbers spaces and delete letters on a separate screen document or notepad. this would make the program much more unique and practical as the program would work in real time and people interacting with the mute and deaf and see what they are "typing" in ASL.
# Instructions
## Setup and Foundations
Firstly, you need both a jetson nano and an actual computer or laptop. We need the laptop as the jetson nano with its standard 32 gig microSD does not have the memory to hold all the required material and therefore cannot train the AI.
Make sure the jetson nano has pip and its libraries installed and up to date, especially pytorch. In fact, make sure your jetson can get the latest version of python 3 to avoid any annoying errors you may get. Learn how to do all of this online (this is my second time writing this as the first time i accidentally obliterated this entire documentation with on swipe of the trackpad okay? please understand i have slight sanity deficiency from this project)
Similarly, make sure you download the latest version of python 3 for your laptop or desktop computer, and install required libraries, especially pytorch (the version of pytorch must match your version of python to be compatible, at least that was what I dealt with)
In file explorer, go to desktop and make a folder titled with your name (I called mine "JacobChanSecondAttempt" but you probably will choose something else so this folder will be referred to as the "base folder.")
In this folder, make two more folders, one titled data and the other titled models. 
On juicetanz's geoguessr project github page (https://github.com/juicetanz/geoguessr-ai/tree/main), download "reshape.py" and make sure it goes to your base folder. 
On Dusty's jetsoninference github page (https://github.com/dusty-nv/pytorch-classification/tree/819b105087c397c23cd81fd9446b5f0a0213db94), download onnx_export.py, voc.py, nuswide.py, and train.py to your base folder. 
Look back at your base folder and you should see these files and a new folder called pycache that has automatically formed. This folder contains the compressed python variants of the files you just downloaded, so DO NOT DELETE IT.
On your jetson (connect and log in via SSH with putty, then go to VScode and add a host (your jetson's IP address) if you haven't already, then connect with the remote button) open the jetson inference folder in the nvidia folder. Make a new folder here titled with just your name or whatever you want to call it. Leave it alone for now. 
(Note: just as a reminder, this program will not export or function on the jetson without a properly updated pip, pytorch and sufficient version of python). 
## Fetching, organizing and fusing the datasets
We will be getting these datasets off of kaggle, BUT WE WILL NOT BE TRAINING ON THERE. DO NOT TRY TO DOWNLOAD PRETRAINED MODELS FROM THERE, THE H5 TO ONNX WILL BE COMPLETE HELL.
Download these datasets: "ASL Alphabet" by Akash, and "American Sign Language (ASL) Dataset" by Prathum Arikeri. Make sure they go to the data folder located in your base folder. This will take a bit of time as each one is a whole giggity gigabyte.
Unzip both of these files. Again, this will take a while. While these folders unzip, prepare yourself for some incoming mental pain and sanity loss. 
Once both datasets have been unzipped, rename "American Sign Language (ASL) Dataset" to whatever you want, just make sure it has no numbers or special symbols that may confuse python when we move it to the jetson for exporting. I renamed mine to "thirdset" as that was the third dataset I downloaded in the development of this project. let's refer to this folder as the "home set folder"
Anyways, going into the home set folder, there will be a folder called american. this is actually the training folder, so rename it to "train" so it will be recognizable by the code in train.py.
As you may know, to train an AI we need a training folder, a test folder, and a val folder. With only a train folder, this set will not work as is. That is where the second set comes in. Open other dataset you downloaded (ASL Alphabet) and open the "asl_alphabet_test" folder. You will see another folder with the same name, click on that. Inside that, you'll see a single image for each ASL symbol in alphabetical order, but this is still incorrectly formatted. take all the images out of the test folder and drop them in the larger test folder. Delete the now empty smaller test folder. Now, in the actual test folder, make an individual folder for every letter, space, delete and nothing symbol and drop each test image into its folder (ex. the folder for the "a" test image would be named "a" obviously).
you will notice that this dataset's test folder has no number test images despite having thousands of number images in the train folder. this is simply a mistake on the creator's part, so duplicate a random image of each number from the train folder and drag them into their individual folders in the test folder. With the test folder now properly formatted, put it in the home set folder and rename this test folder "test".
The home set's train folder as you camn see is missing directories for del, nothing and space. go take those directiories out of the other data set and move it to the home set's train folder. optionally, you can increase the number of images in training folders by adding images from the 2nd data set into the home set. for example, I took the first 1000 images from each letter's folder in the 2nd set and put them into their corresponding folders in the home set. if you have more time for more training, then this is recommended to maximize accuracy when analyzing images with various backgrounds and settings.
Now we have to make the val folder. The val folder is essentially a smaller version of the train folder, so start by duplicating the train folder (in the home set folder, obviously). After it's done duplicating, rename the folder val and open it. inside we will have to essentially make each letter's train folder 1/5 or 2/5 of its original size, depending how fast you want the validation process to go. I'm going 2/5, and how I did this was i minimized the file explorer window by clicking the stop fullscreen button next to the exit "X," hopefully you know where that is. Now the files in the folders are in 5 neat collumns. Basically, hold click at the top of the list and drag down until you reach the bottom of the list (really pull down to make it scroll faster). Drag the cursor horizontally to select 3 of the five collumns, right click once selected, and delete. Repeat this step for every folder in the val folder, but make sure you keep track of where you are, as you do not want to unbalance the training by accidentally fractioning a val folder twice and giving it less images than the other val folders.
Now that we have all the folders, we are (probably) ready to start the training process.
## Training
Now comes the exciting but also boring part. Check for python 3 on your computer and make sure you also have pytorch and other requisites. after that, open Windows PowerShell. This python terminal is where we will execute the training command. In the terminal, type these commands in order:______________________________________________________________________. now, leave it be. your computer's GPU is going to be almost completely occupied, meaning no triple A titles for a day-ish. oh yeah, I sh*t you not, this will take up to an entire day. that's what you call slow cooked lmao. 
## Exporting
once the training is finished or when you cut off training when you believe accuracy is good enough (around 95% and above is what you want to shoot for), you'll notice that the best path of the AI (the vesion with the highest overall accuracy) will be saved in a file called model_best.pth.tar. which is located in the models folder of your base folder. Move the models folder and onnx_export to VScode  
